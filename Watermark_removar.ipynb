{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Installation"
      ],
      "metadata": {
        "id": "lxJhBPg6uR-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone \"https://github.com/m-bain/webvid\""
      ],
      "metadata": {
        "id": "vyqpM3F7UFvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd '/content/webvid'"
      ],
      "metadata": {
        "id": "IehYQ20MUSst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q pandas requests mpi4py\n",
        "!pip install -q tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwK8B124XlgK",
        "outputId": "c8101ae0-77ab-4185-99dd-5a4751ceb079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/101.7 kB\u001b[0m \u001b[31m657.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m92.2/101.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt install tesseract-ocr &> /dev/null\n",
        "# !pip install -q pytesseract"
      ],
      "metadata": {
        "id": "IN4-Zp_XBSQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget 'http://www.robots.ox.ac.uk/~maxbain/webvid/results_2M_train.csv' -O 'results_2M_train.csv' &> /dev/null\n",
        "# !wget 'http://www.robots.ox.ac.uk/~maxbain/webvid/results_10M_train.csv' -O 'results_10M_train.csv' &> /dev/null\n",
        "!wget 'http://www.robots.ox.ac.uk/~maxbain/webvid/results_2M_val.csv' -O 'results_2M_val.csv' &> /dev/null\n",
        "# !wget 'http://www.robots.ox.ac.uk/~maxbain/webvid/results_10M_val.csv' -O 'results_10M_val.csv' &> /dev/null"
      ],
      "metadata": {
        "id": "cz5mXvioI5J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "MCvJ2EciuXkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n"
      ],
      "metadata": {
        "id": "jWG3kGqZjUPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Constants Here"
      ],
      "metadata": {
        "id": "wSotCNKY1T6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_SAVE_DIR = '/content/videos'\n",
        "os.makedirs(VIDEO_SAVE_DIR, exist_ok=True)\n",
        "VIDEO_FRAMES_DIR = '/content/frames'\n",
        "os.makedirs(VIDEO_FRAMES_DIR, exist_ok=True)\n",
        "VIDEOS_OUTPUT_DIR = '/content/videos-output'\n",
        "os.makedirs(VIDEOS_OUTPUT_DIR, exist_ok=True)\n",
        "VIDEOS_OUTPUT_DIR = '/content/frames-output'\n",
        "os.makedirs(VIDEOS_OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "AmGND3af1N2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/results_2M_val.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4P0618xKzayn",
        "outputId": "761d1979-5840-4068-93af-de5fa5b337bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         videoid                                               name  page_idx  \\\n",
              "0     1053841541  Travel blogger shoot a story on top of mountai...     27732   \n",
              "1        5641526          Horse grazing - seperated on green screen     28620   \n",
              "2     1019039938                  City traffic lights. blurred view     22404   \n",
              "3        6251156  Asian girl sexy santa claus isolated greenscre...      4046   \n",
              "4       23720764  Young woman flexing muscles with barbell in gy...     13617   \n",
              "...          ...                                                ...       ...   \n",
              "4994    24154516  Little cute baby girl sitting on the swing and...     21797   \n",
              "4995  1028512643  Waves on the haeundae beach in busan, aerial view     11404   \n",
              "4996  1027291601  Groom with bride standing in cave of mountain ...     24445   \n",
              "4997    24911924  Lonely teenager thinking looking the ocean sit...     26173   \n",
              "4998  1030221938  Lush green banana palm leaf during summer in r...      5265   \n",
              "\n",
              "           page_dir     duration  \\\n",
              "0     027701_027750  PT00H00M17S   \n",
              "1     054101_054150  PT00H00M24S   \n",
              "2     022401_022450  PT00H00M13S   \n",
              "3     004001_004050  PT00H00M16S   \n",
              "4     013601_013650  PT00H00M24S   \n",
              "...             ...          ...   \n",
              "4994  021751_021800  PT00H00M21S   \n",
              "4995  011401_011450  PT00H00M22S   \n",
              "4996  024401_024450  PT00H00M13S   \n",
              "4997  026151_026200  PT00H00M12S   \n",
              "4998  005251_005300  PT00H00M14S   \n",
              "\n",
              "                                             contentUrl  \n",
              "0     https://ak.picdn.net/shutterstock/videos/10538...  \n",
              "1     https://ak.picdn.net/shutterstock/videos/56415...  \n",
              "2     https://ak.picdn.net/shutterstock/videos/10190...  \n",
              "3     https://ak.picdn.net/shutterstock/videos/62511...  \n",
              "4     https://ak.picdn.net/shutterstock/videos/23720...  \n",
              "...                                                 ...  \n",
              "4994  https://ak.picdn.net/shutterstock/videos/24154...  \n",
              "4995  https://ak.picdn.net/shutterstock/videos/10285...  \n",
              "4996  https://ak.picdn.net/shutterstock/videos/10272...  \n",
              "4997  https://ak.picdn.net/shutterstock/videos/24911...  \n",
              "4998  https://ak.picdn.net/shutterstock/videos/10302...  \n",
              "\n",
              "[4999 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87212216-0c85-4fa1-a088-159a95de7ba3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>videoid</th>\n",
              "      <th>name</th>\n",
              "      <th>page_idx</th>\n",
              "      <th>page_dir</th>\n",
              "      <th>duration</th>\n",
              "      <th>contentUrl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1053841541</td>\n",
              "      <td>Travel blogger shoot a story on top of mountai...</td>\n",
              "      <td>27732</td>\n",
              "      <td>027701_027750</td>\n",
              "      <td>PT00H00M17S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/10538...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5641526</td>\n",
              "      <td>Horse grazing - seperated on green screen</td>\n",
              "      <td>28620</td>\n",
              "      <td>054101_054150</td>\n",
              "      <td>PT00H00M24S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/56415...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1019039938</td>\n",
              "      <td>City traffic lights. blurred view</td>\n",
              "      <td>22404</td>\n",
              "      <td>022401_022450</td>\n",
              "      <td>PT00H00M13S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/10190...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6251156</td>\n",
              "      <td>Asian girl sexy santa claus isolated greenscre...</td>\n",
              "      <td>4046</td>\n",
              "      <td>004001_004050</td>\n",
              "      <td>PT00H00M16S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/62511...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23720764</td>\n",
              "      <td>Young woman flexing muscles with barbell in gy...</td>\n",
              "      <td>13617</td>\n",
              "      <td>013601_013650</td>\n",
              "      <td>PT00H00M24S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/23720...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>24154516</td>\n",
              "      <td>Little cute baby girl sitting on the swing and...</td>\n",
              "      <td>21797</td>\n",
              "      <td>021751_021800</td>\n",
              "      <td>PT00H00M21S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/24154...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>1028512643</td>\n",
              "      <td>Waves on the haeundae beach in busan, aerial view</td>\n",
              "      <td>11404</td>\n",
              "      <td>011401_011450</td>\n",
              "      <td>PT00H00M22S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/10285...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>1027291601</td>\n",
              "      <td>Groom with bride standing in cave of mountain ...</td>\n",
              "      <td>24445</td>\n",
              "      <td>024401_024450</td>\n",
              "      <td>PT00H00M13S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/10272...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>24911924</td>\n",
              "      <td>Lonely teenager thinking looking the ocean sit...</td>\n",
              "      <td>26173</td>\n",
              "      <td>026151_026200</td>\n",
              "      <td>PT00H00M12S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/24911...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>1030221938</td>\n",
              "      <td>Lush green banana palm leaf during summer in r...</td>\n",
              "      <td>5265</td>\n",
              "      <td>005251_005300</td>\n",
              "      <td>PT00H00M14S</td>\n",
              "      <td>https://ak.picdn.net/shutterstock/videos/10302...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4999 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87212216-0c85-4fa1-a088-159a95de7ba3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87212216-0c85-4fa1-a088-159a95de7ba3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87212216-0c85-4fa1-a088-159a95de7ba3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c341d6a-f619-4fd6-840e-ab12380a4961\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c341d6a-f619-4fd6-840e-ab12380a4961')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c341d6a-f619-4fd6-840e-ab12380a4961 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQbgqiF7rhui",
        "outputId": "ce8adde1-98e7-489d-8023-ca1cfafde753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['videoid', 'name', 'page_idx', 'page_dir', 'duration', 'contentUrl'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for download video from url and converting it to frames"
      ],
      "metadata": {
        "id": "kA_0cteC5Rks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def url_to_frames(video_url, video_name, video_save_dir=VIDEO_SAVE_DIR, video_frames_dir=VIDEO_FRAMES_DIR):\n",
        "    video_save_path = os.path.join(video_save_dir, f'{video_name}.mp4')\n",
        "    if not os.path.exists(video_save_path):\n",
        "        print('Downloading video from url:', video_url)\n",
        "        urllib.request.urlretrieve(video_url, video_save_path)\n",
        "        print('Video saved to path:', video_save_path)\n",
        "    else:\n",
        "        print('Video already exists at path:', video_save_path)\n",
        "\n",
        "    video_frames_path = os.path.join(video_frames_dir, video_name)\n",
        "    if True or not os.path.exists(video_frames_path):\n",
        "        os.makedirs(video_frames_path, exist_ok=True)\n",
        "        print('Saving video frames at path:', video_frames_path)\n",
        "        cap = cv2.VideoCapture(video_save_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        for frame_count in tqdm(range(total_frames)):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "            image_path = os.path.join(video_frames_path, f\"frame_{frame_count:06d}.jpg\")\n",
        "            cv2.imwrite(image_path, frame)\n",
        "\n",
        "        cap.release()\n",
        "        print('\\nVideo frames saved at path:', video_frames_dir)\n",
        "    else:\n",
        "        print('Video frames directory exists at path:', video_frames_path)\n"
      ],
      "metadata": {
        "id": "3qGmHkVoy00g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df.loc[8, 'contentUrl'])\n",
        "# print(df.loc[11, 'contentUrl'])\n",
        "print(df.loc[15, 'contentUrl'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KcHzBcUGdiH",
        "outputId": "dd40575b-bb36-4f80-8bbc-824e0c9387a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://ak.picdn.net/shutterstock/videos/29797315/preview/stock-footage-aerial-uhd-k-view-mid-air-flight-over-fresh-and-clean-mountain-river-at-sunny-summer-morning.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_index = 15\n",
        "url_to_frames(\n",
        "    video_url=df.loc[video_index, 'contentUrl'],\n",
        "    video_name=str(df.loc[video_index, 'videoid']),\n",
        "    video_save_dir=VIDEO_SAVE_DIR,\n",
        "    video_frames_dir=VIDEO_FRAMES_DIR,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpoMuSSM0bgA",
        "outputId": "84acffe8-59e0-42e9-ad26-ab4bb7a1d063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading video from url: https://ak.picdn.net/shutterstock/videos/29797315/preview/stock-footage-aerial-uhd-k-view-mid-air-flight-over-fresh-and-clean-mountain-river-at-sunny-summer-morning.mp4\n",
            "Video saved to path: /content/videos/29797315.mp4\n",
            "Saving video frames at path: /content/frames/29797315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:08<00:00, 183.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Video frames saved at path: /content/frames\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove frames folder in case not needed\n",
        "# !rm -rf \"/content/webvid/frames/5641526\""
      ],
      "metadata": {
        "id": "mezUkiJbJGag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames_dir = '/content/frames/1053841541'\n",
        "video_frames = sorted(os.listdir(video_frames_dir))\n",
        "image_path = os.path.join(video_frames_dir, video_frames[0])\n",
        "img = Image.open(image_path)\n",
        "width, height = img.size\n",
        "print(f\"Image dimensions: {width} x {height}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jszKi5evth3P",
        "outputId": "da6f6a96-ddd5-455d-f9dc-a7887cd3fde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image dimensions: 596 x 336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "watermark_path = '/content/frames/1040044910/frame_000000.jpg'\n",
        "watermark_mask = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
        "_, watermark_mask = cv2.threshold(watermark_mask, 200, maxval=255, type=cv2.THRESH_OTSU)\n",
        "watermark_mask = cv2.bitwise_not(watermark_mask)\n",
        "# dilatekernel = np.ones((25, 25), 'uint8')\n",
        "# watermark_mask = cv2.dilate(watermark_mask, dilatekernel)\n",
        "cv2.imwrite('/content/watermark_mask.jpg', watermark_mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE39Lx41o9Ek",
        "outputId": "de99e544-39f6-456d-a776-a0e883f5996a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1 - OpenCV Inpaint - (Poor Results)"
      ],
      "metadata": {
        "id": "FAG4nBVJXWx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_frames_dir = '/content/webvid/frames/1053841541'\n",
        "video_frames = sorted(os.listdir(video_frames_dir))\n",
        "\n",
        "watermark_path = '/content/webvid/frames/1040044910/frame_000000.jpg'\n",
        "watermark_mask = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
        "_, watermark_mask = cv2.threshold(watermark_mask, 200, maxval=255, type=cv2.THRESH_OTSU)\n",
        "watermark_mask = cv2.bitwise_not(watermark_mask)\n",
        "dilatekernel = np.ones((11, 11), 'uint8')\n",
        "watermark_mask = cv2.dilate(watermark_mask, dilatekernel)\n",
        "\n",
        "i = 100\n",
        "frame1 = os.path.join(video_frames_dir, video_frames[i])\n",
        "image1 = cv2.imread(frame1, cv2.IMREAD_COLOR)\n",
        "frame2 = os.path.join(video_frames_dir, video_frames[i+1])\n",
        "image2 = cv2.imread(frame2, cv2.IMREAD_COLOR)\n",
        "\n",
        "# remove watermark with mark\n",
        "# print('[watermark_mask]', watermark_mask.shape)\n",
        "# print('[image1]', image1.shape)\n",
        "# print('[image2]', image2.shape)\n",
        "watermark_mask = cv2.resize(watermark_mask, (image1.shape[1], image1.shape[0]))\n",
        "output1 = cv2.inpaint(image1, watermark_mask, 3, flags=cv2.INPAINT_NS)\n",
        "output2 = cv2.inpaint(image2, watermark_mask, 3, flags=cv2.INPAINT_NS)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(3, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(3, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(3, 2, 3)\n",
        "plt.imshow(cv2.cvtColor(output1, cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(3, 2, 4)\n",
        "plt.imshow(cv2.cvtColor(output2, cv2.COLOR_BGR2RGB))\n",
        "plt.subplot(3, 2, 5)\n",
        "plt.imshow(cv2.cvtColor(watermark_mask, cv2.COLOR_BGR2RGB))\n"
      ],
      "metadata": {
        "id": "HeIbldqtBPSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# video_frames_dir = '/content/webvid/frames/1053841541'\n",
        "# video_frames = sorted(os.listdir(video_frames_dir))\n",
        "# output_frames_dir = '/content/webvid/frames-output/1053841541'\n",
        "# os.makedirs(output_frames_dir, exist_ok=True)\n",
        "\n",
        "# watermark_path = '/content/webvid/frames/1040044910/frame_000000.jpg'\n",
        "# watermark_mask = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
        "# _, watermark_mask = cv2.threshold(watermark_mask, 200, maxval=255, type=cv2.THRESH_OTSU)\n",
        "# watermark_mask = cv2.bitwise_not(watermark_mask)\n",
        "# # dilatekernel = np.ones((11, 11), 'uint8')\n",
        "# # watermark_mask = cv2.dilate(watermark_mask, dilatekernel)\n",
        "\n",
        "# for i in tqdm(range(len(video_frames))):\n",
        "#     frame_path = os.path.join(video_frames_dir, video_frames[i])\n",
        "#     image = cv2.imread(frame_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "#     # remove watermark with mark\n",
        "#     watermark_mask = cv2.resize(watermark_mask, (image.shape[1], image.shape[0]))\n",
        "#     output = cv2.inpaint(image, watermark_mask, 3, flags=cv2.INPAINT_NS)\n",
        "\n",
        "#     output_path = os.path.join(output_frames_dir, video_frames[i])\n",
        "#     cv2.imwrite(output_path, output)\n",
        "\n",
        "#     # plt.figure(figsize=(15, 25))\n",
        "#     # titles = ['image', 'output']\n",
        "#     # plot_imgs = [image, output]\n",
        "#     # for j, img in enumerate(plot_imgs):\n",
        "#     #     plt.subplot(5, len(plot_imgs), i*len(plot_imgs) + j + 1)\n",
        "#     #     plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "#     #     if i == 0: plt.title(titles[j])\n",
        "#     #     plt.axis('off')\n",
        "#     # plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "bwC6Xk3H-aBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video to Video (OpenCV) - Poor Results\n",
        "\n",
        "Load video frames, remove watermark, save new frame to output video file."
      ],
      "metadata": {
        "id": "ewQEaIaOhhzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "watermark_path = '/content/frames/1040044910/frame_000000.jpg'\n",
        "watermark_mask = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
        "print('[watermark_mask]', watermark_mask.shape)\n",
        "_, watermark_mask = cv2.threshold(watermark_mask, 200, maxval=255, type=cv2.THRESH_OTSU)\n",
        "watermark_mask = cv2.bitwise_not(watermark_mask)\n",
        "dilatekernel = np.ones((3, 3), 'uint8')\n",
        "watermark_mask = cv2.dilate(watermark_mask, dilatekernel)\n",
        "\n",
        "input_video_path = '/content/videos/30287869.mp4'\n",
        "input_video = cv2.VideoCapture(input_video_path)\n",
        "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(int(input_video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_video_path = '/content/videos-output/30287869.mp4'\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, 20.0, (width, height))\n",
        "\n",
        "for i in tqdm(range(total_frames)):\n",
        "    # input input_frame\n",
        "    ret, input_frame = input_video.read()\n",
        "    if not ret: break\n",
        "    # remove watermark\n",
        "    watermark_mask = cv2.resize(watermark_mask, (input_frame.shape[1], input_frame.shape[0]))\n",
        "    output_frame = cv2.inpaint(input_frame, watermark_mask, 3, flags=cv2.INPAINT_NS)\n",
        "    # write the output_frame\n",
        "    output_video.write(output_frame)\n",
        "\n",
        "# Release everything if job is finished\n",
        "input_video.release()\n",
        "output_video.release()\n"
      ],
      "metadata": {
        "id": "Miqt8NsCdoIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2 - WDNet GAN - (Poor Results)"
      ],
      "metadata": {
        "id": "cMk22ezjXjcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/MRUIL/WDNet.git\""
      ],
      "metadata": {
        "id": "VsmEG8dkxhjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1Tv0iM3ZbM0j3akP9uI1myC18IUnyDNjL\" -O \"WDNet_G.pkl\""
      ],
      "metadata": {
        "id": "CBMrbSBiG0dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if '/content/WDNet' not in sys.path: sys.path.append('/content/WDNet')\n",
        "from WDNet import generator\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('[device]', device)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"1\"\n",
        "\n",
        "G = generator(3, 3)\n",
        "G.eval()\n",
        "G.load_state_dict(torch.load('WDNet_G.pkl', map_location='cpu'))\n",
        "G.cuda()\n",
        "G\n"
      ],
      "metadata": {
        "id": "_5mKuNYf7bVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "video_frames_dir = '/content/frames/1053841541'\n",
        "video_frames = sorted(os.listdir(video_frames_dir))\n",
        "image_path = os.path.join(video_frames_dir, video_frames[0])\n",
        "img_J = Image.open(image_path)\n",
        "\n",
        "img_source = transform_norm(img_J)\n",
        "img_source = torch.unsqueeze(img_source.cuda(), 0)\n",
        "\n",
        "print('[img_source]', img_source.shape)\n",
        "pred_target, mask, alpha, w, I_watermark = G(img_source)\n",
        "print(type(pred_target), type(mask), type(alpha), type(w), type(I_watermark))\n",
        "print('[pred_target, mask, alpha, w, I_watermark]')\n",
        "print(pred_target.shape, mask.shape, alpha.shape, w.shape, I_watermark.shape)\n",
        "print(pred_target.dtype, mask.dtype, alpha.dtype, w.dtype, I_watermark.dtype)\n",
        "\n",
        "p0 = torch.squeeze(img_source)\n",
        "print('[p0]', p0.shape)\n",
        "p1 = torch.squeeze(pred_target)\n",
        "print('[p1]', p1.shape)\n",
        "p2 = mask\n",
        "print('[p2]', p2.shape)\n",
        "p3 = torch.squeeze(w*mask)\n",
        "print('[p3]', p3.shape)\n",
        "p2 = torch.squeeze(torch.cat([p2,p2,p2],1))\n",
        "print('[p2]', p2.shape)\n",
        "p0 = torch.cat([p0,p1],1)\n",
        "print('[p0]', p0.shape)\n",
        "p2 = torch.cat([p2,p3],1)\n",
        "print('[p2]', p2.shape)\n",
        "p0 = torch.cat([p0,p2],2)\n",
        "print('[p0]', p0.shape)\n",
        "p0 = transforms.ToPILImage()(p0.detach().cpu()).convert('RGB')\n",
        "\n",
        "pred_target = transforms.ToPILImage()(p1.detach().cpu()).convert('RGB')\n",
        "pred_target.save('output.jpg')\n"
      ],
      "metadata": {
        "id": "0Cdykkn9QLOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToPILImage()(mask.detach().cpu().squeeze()).convert('RGB')"
      ],
      "metadata": {
        "id": "Yq0Vni1TQ55-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_target"
      ],
      "metadata": {
        "id": "6pSpztIMT9Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p0"
      ],
      "metadata": {
        "id": "eJmUpjfwR1mL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video to Video (DNN) - Better Results\n",
        "\n",
        "Load video frames, remove watermark, save new frame to output video file."
      ],
      "metadata": {
        "id": "RegcO5A0TRVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_norm = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "input_video_path = '/content/videos/30287869.mp4'\n",
        "input_video = cv2.VideoCapture(input_video_path)\n",
        "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(int(input_video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_video_path = '/content/videos-output/30287869.mp4'\n",
        "output_video = None\n",
        "\n",
        "for i in tqdm(range(total_frames)):\n",
        "    # input input_frame\n",
        "    ret, input_frame = input_video.read()\n",
        "    if not ret: break\n",
        "\n",
        "    # remove watermark\n",
        "    image_pil = Image.fromarray(input_frame)\n",
        "    image_tensor = transform_norm(image_pil)\n",
        "    image_tensor = torch.unsqueeze(image_tensor.cuda(), 0)\n",
        "    pred_target, mask, alpha, w, I_watermark = G(image_tensor)\n",
        "    pred_target = transforms.ToPILImage()(pred_target.detach().cpu().squeeze()).convert('RGB')\n",
        "\n",
        "    # write the output_frame\n",
        "    output_frame = np.array(pred_target)\n",
        "    if output_video is None:\n",
        "        width = output_frame.shape[1]\n",
        "        height = output_frame.shape[0]\n",
        "        output_video = cv2.VideoWriter(output_video_path, fourcc, 20.0, (width, height))\n",
        "    output_video.write(output_frame)\n",
        "\n",
        "# Release everything if job is finished\n",
        "input_video.release()\n",
        "output_video.release()\n"
      ],
      "metadata": {
        "id": "F45qhv_2TRVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Postprocess using opencv"
      ],
      "metadata": {
        "id": "jGm2A9_hXuc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "watermark_path = '/content/frames/1040044910/frame_000000.jpg'\n",
        "watermark_mask = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
        "print('[watermark_mask]', watermark_mask.shape)\n",
        "_, watermark_mask = cv2.threshold(watermark_mask, 200, maxval=255, type=cv2.THRESH_OTSU)\n",
        "watermark_mask = cv2.bitwise_not(watermark_mask)\n",
        "dilatekernel = np.ones((3, 3), 'uint8')\n",
        "watermark_mask = cv2.dilate(watermark_mask, dilatekernel)\n",
        "\n",
        "input_video_path = '/content/videos-output/30287869.mp4'\n",
        "input_video = cv2.VideoCapture(input_video_path)\n",
        "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(int(input_video.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_video_path = '/content/videos-output/30287869-postprocess.mp4'\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, 20.0, (width, height))\n",
        "\n",
        "for i in tqdm(range(total_frames)):\n",
        "    # input input_frame\n",
        "    ret, input_frame = input_video.read()\n",
        "    if not ret: break\n",
        "    # remove watermark\n",
        "    watermark_mask = cv2.resize(watermark_mask, (input_frame.shape[1], input_frame.shape[0]))\n",
        "    output_frame = cv2.inpaint(input_frame, watermark_mask, 3, flags=cv2.INPAINT_NS)\n",
        "    # write the output_frame\n",
        "    output_video.write(output_frame)\n",
        "\n",
        "# Release everything if job is finished\n",
        "input_video.release()\n",
        "output_video.release()\n"
      ],
      "metadata": {
        "id": "YBDMC0SRXCuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3 - ProPainter - (Best Results)"
      ],
      "metadata": {
        "id": "5eKnjnZAhxfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/sczhou/ProPainter.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLlsi3odh1Ds",
        "outputId": "0be91ef7-030e-484d-fa7d-5b6f447c4979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ProPainter'...\n",
            "remote: Enumerating objects: 593, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 593 (delta 30), reused 92 (delta 24), pack-reused 481\u001b[K\n",
            "Receiving objects: 100% (593/593), 55.21 MiB | 15.49 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/ProPainter\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq6HkNKhh1og",
        "outputId": "2b72edef-1662-4ef0-ee28-9816af17bc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ProPainter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install python dependencies\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "dmnXIVmbh7HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # The first example (object removal)\n",
        "# !python inference_propainter.py --video inputs/object_removal/bmx-trees --mask inputs/object_removal/bmx-trees_mask\n",
        "# # The second example (video completion)\n",
        "# !python inference_propainter.py --video inputs/video_completion/running_car.mp4 --mask inputs/video_completion/mask_square.png --height 240 --width 432\n"
      ],
      "metadata": {
        "id": "nYtEQLcBh8Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_propainter.py \\\n",
        "    --video \"/content/videos/30287869.mp4\" \\\n",
        "    --mask \"/content/watermark_mask.jpg\" \\\n",
        "    --fp16 \\\n",
        "    --subvideo_length 40\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwrQ6qdDij0P",
        "outputId": "8c10f18e-db0a-4122-c29e-67b6a732719b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained flow completion model has loaded...\n",
            "Pretrained ProPainter has loaded...\n",
            "Network [InpaintGenerator] was created. Total number of parameters: 39.4 million. To see the architecture, do print(network).\n",
            "\n",
            "Processing: 30287869 [1022 frames]...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ProPainter/inference_propainter.py\", line 350, in <module>\n",
            "    pred_flows_bi_sub, _ = fix_flow_complete.forward_bidirect_flow(\n",
            "  File \"/content/ProPainter/model/recurrent_flow_completion.py\", line 332, in forward_bidirect_flow\n",
            "    pred_flows_backward, pred_edges_backward = self.forward(masked_flows_backward, masks_backward)\n",
            "  File \"/content/ProPainter/model/recurrent_flow_completion.py\", line 300, in forward\n",
            "    flow = self.upsample(feat_d1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 215, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/ProPainter/model/recurrent_flow_completion.py\", line 141, in forward\n",
            "    x = F.interpolate(x,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 4020, in interpolate\n",
            "    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 608.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 328.81 MiB is free. Process 345530 has 14.42 GiB memory in use. Of the allocated memory 11.72 GiB is allocated by PyTorch, and 1.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhqpJvz7ptxr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}